{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KernelDensity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Data into Pandas Dataframe\n",
    "cov_df2 = pd.read_csv('covtype.data.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVERTYPE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming Column\n",
    "#Creating Seperate Data Columns\n",
    "cov_df2 = cov_df2.rename(columns={'5': 'Forest_cov_desig.'})\n",
    "class_2 = cov_df2[cov_df2['Forest_cov_desig.'] == 2]\n",
    "class_1 = cov_df2[cov_df2['Forest_cov_desig.'] == 1]\n",
    "class_3 = cov_df2[cov_df2['Forest_cov_desig.'] == 3]\n",
    "class_7 = cov_df2[cov_df2['Forest_cov_desig.'] == 7]\n",
    "class_6 = cov_df2[cov_df2['Forest_cov_desig.'] == 6]\n",
    "class_5 = cov_df2[cov_df2['Forest_cov_desig.'] == 5]\n",
    "class_4 = cov_df2[cov_df2['Forest_cov_desig.'] == 4]\n",
    "\n",
    "#Since the Dataset was way too big and my computer couldn't handle it, I decided to make \n",
    "#it the same 30000 row set like the paper. I kept the same percentage of each class and\n",
    "# cut each class down by the same ratio. The ratio g is below.\n",
    "# This code picks the number of random samples and cuts down dataset by the ratio. \n",
    "g = 30000/581011\n",
    "class_2 = class_2.sample(frac=g, replace = False).reset_index(drop=True)\n",
    "class_1 = class_1.sample(frac=g, replace = False).reset_index(drop=True)\n",
    "class_3 = class_3.sample(frac=g, replace = False).reset_index(drop=True)\n",
    "class_7 = class_7.sample(frac=g, replace = False).reset_index(drop=True)\n",
    "class_6 = class_6.sample(frac=g, replace = False).reset_index(drop=True)\n",
    "class_5 = class_5.sample(frac=g, replace = False).reset_index(drop=True)\n",
    "class_4 = class_4.sample(frac=g, replace = False).reset_index(drop=True)\n",
    "frames = [class_2, class_1, class_3, class_7, class_6, class_5, class_4]\n",
    "\n",
    "#Combined data columns into a dataframe.\n",
    "cov_df2 = pd.concat(frames)\n",
    "#Changed class to 1 and 0 using .map to have largest class as 1 and the rest as 0.\n",
    "class_map = {1: 0, 2: 1, 3: 0,\n",
    "              4: 0, 5: 0, 6: 0, 7: 0}\n",
    "cov_df2['Class'] = cov_df2['Forest_cov_desig.'].map(class_map)\n",
    "cov_df2 = cov_df2.drop(['Forest_cov_desig.'], axis = 1)\n",
    "#Shuffling data and converting into numpy array.\n",
    "cov_df2 = shuffle(cov_df2)\n",
    "cov_arr = cov_df2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy function. Compares predicted labels vs actual labels and counts accuracy.\n",
    "def prediction(predictions, Y_given):\n",
    "    wrong = 0\n",
    "    counter = 0\n",
    "    for test, train in zip(predictions, Y_given):\n",
    "        if test == train:\n",
    "            wrong = wrong\n",
    "        else:\n",
    "            wrong = wrong + 1\n",
    "        counter = counter + 1\n",
    "    accuracy = 1 - (wrong/counter)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'kernel': 'linear'}\n",
      "Train accuracy: 0.764\n",
      "Test accuracy: 0.76076\n",
      "Best params: {'C': 0.1, 'kernel': 'linear'}\n",
      "Train accuracy: 0.7668\n",
      "Test accuracy: 0.7628\n",
      "Best params: {'C': 0.1, 'kernel': 'linear'}\n",
      "Train accuracy: 0.7766\n",
      "Test accuracy: 0.7587200000000001\n"
     ]
    }
   ],
   "source": [
    "#Three lists to store training accuracy for each trial, test accuracy for each trial, and best parameters for each trial.\n",
    "SVM_train_accuracy = []\n",
    "SVM_test_accuracy = []\n",
    "SVM_best_params = []\n",
    "\n",
    "#For each Trial\n",
    "for i in range(3):\n",
    "    data_svm = shuffle(cov_arr)\n",
    "#Data splitting, train-test-split.\n",
    "    X_svm = data_svm[:, 0:-1]\n",
    "    Y_svm = data_svm[:, -1]\n",
    "    X_train_svm, X_test_svm, Y_train_svm, Y_test_svm = train_test_split(X_svm, Y_svm, test_size = 5/6, random_state=42)\n",
    "#Scaling training data using StandardScaler\n",
    "    scaler_svm = preprocessing.StandardScaler().fit(X_train_svm)\n",
    "    X_train_svm = scaler_svm.transform(X_train_svm)\n",
    "#Param-grid, setting SVM class,grid search parameters, and fitting training data.\n",
    "    parameters = [{'kernel': ['rbf'], 'gamma': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0], 'C': [10**-7, 10**-6, 10**-5,\n",
    "                                                                                                     10**-4, 10**-3, 10**-2,\n",
    "                                                                                                     10**-1]},\n",
    "                  {'kernel': ['poly'], 'degree': [2, 3], 'C': [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1]},\n",
    "                  {'kernel': ['linear'], 'C': [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1]}]\n",
    "    svc = svm.SVC(gamma = 'auto')\n",
    "    grid_search_svm = GridSearchCV(svc, parameters, cv = 5, error_score = np.nan)\n",
    "    grid_search2_svm = grid_search_svm.fit(X_train_svm, Y_train_svm)\n",
    "    best_params_svm = grid_search2_svm.best_params_\n",
    "#Printing and storing best params into list.\n",
    "    print(\"Best params: {}\".format(best_params_svm))\n",
    "    SVM_best_params.append('Trial ' + str(i + 1) + ': ' + str(best_params_svm))\n",
    "#Using best_estimator to predict training data labels.\n",
    "#Using prediction function to calculate training accuracy.\n",
    "#Printing and storing training accuracies into list.\n",
    "    train_predictions_svm = grid_search2_svm.best_estimator_.predict(X_train_svm) #.best_estimator_\n",
    "    train_accuracy_svm = prediction(train_predictions_svm, Y_train_svm)\n",
    "    print(\"Train accuracy: {}\".format(train_accuracy_svm))\n",
    "    SVM_train_accuracy.append('Trial ' + str(i + 1) + ': ' + str(train_accuracy_svm))\n",
    "#Scaling testing data with my training data scaler. This ensures training and testing data are scaled the same.\n",
    "#Using prediction function to calculate testing accuracy.\n",
    "#Printing and storing test accuracy into list.\n",
    "    X_test_svm = scaler_svm.transform(X_test_svm)\n",
    "    test_predictions_svm = grid_search2_svm.best_estimator_.predict(X_test_svm) #.best_estimator_\n",
    "    test_accuracy_svm = prediction(test_predictions_svm, Y_test_svm)\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_svm))\n",
    "    SVM_test_accuracy.append('Trial ' + str(i + 1) + ': ' + str(test_accuracy_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.77932\n",
      "Best params: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.77568\n",
      "Best params: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "#Three lists to store training accuracy for each trial, test accuracy for each trial, and best parameters for each trial.\n",
    "kNN_train_accuracy = []\n",
    "kNN_test_accuracy = []\n",
    "kNN_best_params = []\n",
    "\n",
    "#Setting K parameters\n",
    "p = (np.linspace(1,500,25))\n",
    "p = p.astype('int64')\n",
    "\n",
    "#For each trial\n",
    "for i in range(3):\n",
    "    data_knn = shuffle(cov_arr)\n",
    "#Data splitting, train-test-split\n",
    "    X_knn = data_knn[:, 0:-1]\n",
    "    Y_knn = data_knn[:, -1]\n",
    "    X_train_knn, X_test_knn, Y_train_knn, Y_test_knn = train_test_split(X_knn, Y_knn, test_size = 5/6, random_state=42)\n",
    "# Scaling training data using StandardScaler()\n",
    "    scaler_knn = preprocessing.StandardScaler().fit(X_train_knn)\n",
    "    X_train_knn = scaler_knn.transform(X_train_knn)\n",
    "#Param-grid, initializing kNN class, grid search parameters and fitting training data.\n",
    "# Printing and storing best parameters in list.\n",
    "    params = [{'weights' : ['uniform', 'distance'], 'metric' : ['minkowski'],'n_neighbors': p}]\n",
    "    neighbor = KNeighborsClassifier()\n",
    "    grid_search_knn = GridSearchCV(neighbor, params, cv=5, error_score = np.nan)\n",
    "    grid_search_knn2 = grid_search_knn.fit(X_train_knn, Y_train_knn)\n",
    "    best_params_knn = grid_search_knn2.best_params_\n",
    "    print(\"Best params: {}\".format(best_params_knn))\n",
    "    kNN_best_params.append('Trial ' + str(i + 1) + ': ' + str(best_params_knn))\n",
    "#Using best_estimator to predict training data labels.\n",
    "#Using prediction function to calculate training accuracy\n",
    "#Printing and storing training accuracy into list.\n",
    "    train_predictions_knn = grid_search_knn2.best_estimator_.predict(X_train_knn)\n",
    "    train_accuracy_knn = prediction(train_predictions_knn, Y_train_knn)\n",
    "    print(\"Train accuracy: {}\".format(train_accuracy_knn))\n",
    "    kNN_train_accuracy.append('Trial ' + str(i + 1) + ': ' + str(train_accuracy_knn))\n",
    "#Scaling testing data with my training data scaler. This ensures training and testing data are scaled the same.\n",
    "#Using prediction function to calculate testing accuracy.\n",
    "#Printing and storing test accuracy into list.\n",
    "    X_test_knn = scaler_knn.transform(X_test_knn)\n",
    "    test_predictions_knn = grid_search_knn2.best_estimator_.predict(X_test_knn)\n",
    "    test_accuracy_knn = prediction(test_predictions_knn, Y_test_knn)\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_knn))\n",
    "    kNN_test_accuracy.append('Trial ' + str(i + 1) + ': ' + str(test_accuracy_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_features': 6, 'n_estimators': 1024}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8218\n",
      "Best params: {'max_features': 2, 'n_estimators': 1024}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.81464\n",
      "Best params: {'max_features': 12, 'n_estimators': 1024}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.82608\n"
     ]
    }
   ],
   "source": [
    "#Three lists to store training accuracy for each trial, test accuracy for each trial, and best parameters for each trial.\n",
    "rf_train_accuracy = []\n",
    "rf_test_accuracy = []\n",
    "rf_best_params = []\n",
    "\n",
    "#For each trial\n",
    "for i in range(3):\n",
    "    data_rf = shuffle(cov_arr)\n",
    "#Data splitting, train-test-split\n",
    "    X_rf = data_rf[:, 0:-1]\n",
    "    Y_rf = data_rf[:, -1]\n",
    "    X_train_rf, X_test_rf, Y_train_rf, Y_test_rf = train_test_split(X_rf, Y_rf, test_size = 5/6, random_state=42)\n",
    "#Param-grid, initialize random forest class, and fitting training data with grid search.\n",
    "    params = [{'n_estimators' : [1024], 'max_features' : [1, 2, 4, 6, 8, 12, 16, 20]}]\n",
    "    forest = RandomForestClassifier()\n",
    "    grid_search_rf = GridSearchCV(forest, params, cv=5, error_score = np.nan)\n",
    "    grid_search_rf2 = grid_search_rf.fit(X_train_rf, Y_train_rf)\n",
    "#Printing and storing best params into list.\n",
    "    best_params_rf = grid_search_rf2.best_params_\n",
    "    print(\"Best params: {}\".format(best_params_rf))\n",
    "    rf_best_params.append('Trial ' + str(i + 1) + ': ' + str(best_params_rf))\n",
    "#Using best_estimator to predict training data.\n",
    "#Storing and printing training accuracy into list.\n",
    "#Using defined prediction function to calculate total accuracy.\n",
    "    train_predictions_rf = grid_search_rf2.best_estimator_.predict(X_train_rf)\n",
    "    train_accuracy_rf = prediction(train_predictions_rf, Y_train_rf)\n",
    "    print(\"Train accuracy: {}\".format(train_accuracy_rf))\n",
    "    rf_train_accuracy.append('Trial ' + str(i + 1) + ': ' + str(train_accuracy_rf))\n",
    "#Predicting Test data with best_estimator.predict.\n",
    "#Using prediction function to calculate accuracy.\n",
    "#Printing and storing Test accuracy into list.\n",
    "    test_predictions_rf = grid_search_rf2.best_estimator_.predict(X_test_rf)\n",
    "    test_accuracy_rf = prediction(test_predictions_rf, Y_test_rf)\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_rf))\n",
    "    rf_test_accuracy.append('Trial ' + str(i + 1) + ': ' + str(test_accuracy_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
