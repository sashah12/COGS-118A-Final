{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KernelDensity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset into Pandas Dataframe\n",
    "df3 = pd.read_csv('letter-recognition.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Dataset P.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Column\n",
    "letter_df = df3\n",
    "letter_df = letter_df.rename(columns={'T': 'Letter'})\n",
    "#Initialize Column\n",
    "letter_df['Class'] = 0\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
    "#For each row in the dataframe, if the alphabet letter in that row is not in the list above,\n",
    "# set the class of that data point to 0. Otherwise, it's 1.\n",
    "for index, row in letter_df.iterrows():\n",
    "    if row['Letter'] in letters:\n",
    "        letter_df.at[index, 'Class'] = 1\n",
    "letter_df = letter_df.drop(['Letter'], axis = 1)\n",
    "#Converting dataframe into array.\n",
    "letter_arr = letter_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy function. Compares predicted labels vs actual labels and counts accuracy.\n",
    "def prediction(predictions, Y_given):\n",
    "    wrong = 0\n",
    "    counter = 0\n",
    "    for test, train in zip(predictions, Y_given):\n",
    "        if test == train:\n",
    "            wrong = wrong\n",
    "        else:\n",
    "            wrong = wrong + 1\n",
    "        counter = counter + 1\n",
    "    accuracy = 1 - (wrong/counter)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Train accuracy: 0.9566\n",
      "Test accuracy: 0.8923261550770052\n",
      "Best params: {'C': 0.1, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Train accuracy: 0.9672\n",
      "Test accuracy: 0.9193279551970132\n",
      "Best params: {'C': 0.1, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Train accuracy: 0.9502\n",
      "Test accuracy: 0.8862590839389293\n"
     ]
    }
   ],
   "source": [
    "#Three lists to store training accuracy for each trial, test accuracy for each trial, and best parameters for each trial.\n",
    "SVM_train_accuracy = []\n",
    "SVM_test_accuracy = []\n",
    "SVM_best_params = []\n",
    "\n",
    "#For each Trial\n",
    "for i in range(3):\n",
    "    data_svm = shuffle(letter_arr)\n",
    "#Data splitting, train-test-split.\n",
    "    X_svm = data_svm[:, 0:-1]\n",
    "    Y_svm = data_svm[:, -1]\n",
    "    X_train_svm, X_test_svm, Y_train_svm, Y_test_svm = train_test_split(X_svm, Y_svm, test_size = 14999/19999, random_state=42)\n",
    "#Scaling training data using StandardScaler\n",
    "    scaler_svm = preprocessing.StandardScaler().fit(X_train_svm)\n",
    "    X_train_svm = scaler_svm.transform(X_train_svm)\n",
    "#Param-grid, setting SVM class,grid search parameters, and fitting training data.\n",
    "    parameters = [{'kernel': ['rbf'], 'gamma': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0], 'C': [10**-7, 10**-6, 10**-5,\n",
    "                                                                                                     10**-4, 10**-3, 10**-2,\n",
    "                                                                                                     10**-1]},\n",
    "                  {'kernel': ['poly'], 'degree': [2, 3], 'C': [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1]},\n",
    "                  {'kernel': ['linear'], 'C': [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1]}]\n",
    "    svc = svm.SVC(gamma = 'auto')\n",
    "    grid_search_svm = GridSearchCV(svc, parameters, cv = 5, error_score = np.nan)\n",
    "    grid_search2_svm = grid_search_svm.fit(X_train_svm, Y_train_svm)\n",
    "    best_params_svm = grid_search2_svm.best_params_\n",
    "#Printing and storing best params into list.\n",
    "    print(\"Best params: {}\".format(best_params_svm))\n",
    "    SVM_best_params.append('Trial ' + str(i + 1) + ': ' + str(best_params_svm))\n",
    "#Using best_estimator to predict training data labels.\n",
    "#Using prediction function to calculate training accuracy.\n",
    "#Printing and storing training accuracies into list.\n",
    "    train_predictions_svm = grid_search2_svm.best_estimator_.predict(X_train_svm) #.best_estimator_\n",
    "    train_accuracy_svm = prediction(train_predictions_svm, Y_train_svm)\n",
    "    print(\"Train accuracy: {}\".format(train_accuracy_svm))\n",
    "    SVM_train_accuracy.append('Trial ' + str(i + 1) + ': ' + str(train_accuracy_svm))\n",
    "#Scaling testing data with my training data scaler. This ensures training and testing data are scaled the same.\n",
    "#Using prediction function to calculate testing accuracy.\n",
    "#Printing and storing test accuracy into list.\n",
    "    X_test_svm = scaler_svm.transform(X_test_svm)\n",
    "    test_predictions_svm = grid_search2_svm.best_estimator_.predict(X_test_svm) #.best_estimator_\n",
    "    test_accuracy_svm = prediction(test_predictions_svm, Y_test_svm)\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_svm))\n",
    "    SVM_test_accuracy.append('Trial ' + str(i + 1) + ': ' + str(test_accuracy_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.950530035335689\n",
      "Best params: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.9535302353490233\n",
      "Best params: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.9537302486832455\n"
     ]
    }
   ],
   "source": [
    "#Three lists to store training accuracy for each trial, test accuracy for each trial, and best parameters for each trial.\n",
    "kNN_train_accuracy = []\n",
    "kNN_test_accuracy = []\n",
    "kNN_best_params = []\n",
    "\n",
    "#Setting K parameters\n",
    "p = (np.linspace(1,500,25))\n",
    "p = p.astype('int64')\n",
    "\n",
    "#For each trial\n",
    "for i in range(3):\n",
    "    data_knn = shuffle(letter_arr)\n",
    "#Data splitting, train-test-split\n",
    "    X_knn = data_knn[:, 0:-1]\n",
    "    Y_knn = data_knn[:, -1]\n",
    "    X_train_knn, X_test_knn, Y_train_knn, Y_test_knn = train_test_split(X_knn, Y_knn, test_size = 14999/19999, random_state=42)\n",
    "# Scaling training data using StandardScaler()\n",
    "    scaler_knn = preprocessing.StandardScaler().fit(X_train_knn)\n",
    "    X_train_knn = scaler_knn.transform(X_train_knn)\n",
    "#Param-grid, initializing kNN class, grid search parameters and fitting training data.\n",
    "# Printing and storing best parameters in list.\n",
    "    params = [{'weights' : ['uniform', 'distance'], 'metric' : ['minkowski'],'n_neighbors': p}]\n",
    "    neighbor = KNeighborsClassifier()\n",
    "    grid_search_knn = GridSearchCV(neighbor, params, cv=5, error_score = np.nan)\n",
    "    grid_search_knn2 = grid_search_knn.fit(X_train_knn, Y_train_knn)\n",
    "    best_params_knn = grid_search_knn2.best_params_\n",
    "    print(\"Best params: {}\".format(best_params_knn))\n",
    "    kNN_best_params.append('Trial ' + str(i + 1) + ': ' + str(best_params_knn))\n",
    "#Using best_estimator to predict training data labels.\n",
    "#Using prediction function to calculate training accuracy\n",
    "#Printing and storing training accuracy into list.\n",
    "    train_predictions_knn = grid_search_knn2.best_estimator_.predict(X_train_knn)\n",
    "    train_accuracy_knn = prediction(train_predictions_knn, Y_train_knn)\n",
    "    print(\"Train accuracy: {}\".format(train_accuracy_knn))\n",
    "    kNN_train_accuracy.append('Trial ' + str(i + 1) + ': ' + str(train_accuracy_knn))\n",
    "#Scaling testing data with my training data scaler. This ensures training and testing data are scaled the same.\n",
    "#Using prediction function to calculate testing accuracy.\n",
    "#Printing and storing test accuracy into list.\n",
    "    X_test_knn = scaler_knn.transform(X_test_knn)\n",
    "    test_predictions_knn = grid_search_knn2.best_estimator_.predict(X_test_knn)\n",
    "    test_accuracy_knn = prediction(test_predictions_knn, Y_test_knn)\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_knn))\n",
    "    kNN_test_accuracy.append('Trial ' + str(i + 1) + ': ' + str(test_accuracy_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_features': 4, 'n_estimators': 1024}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.9449963330888725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_features': 4, 'n_estimators': 1024}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.9455963730915394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:545: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\zingb\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_features': 2, 'n_estimators': 1024}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.9453963597573172\n"
     ]
    }
   ],
   "source": [
    "#Three lists to store training accuracy for each trial, test accuracy for each trial, and best parameters for each trial.\n",
    "rf_train_accuracy = []\n",
    "rf_test_accuracy = []\n",
    "rf_best_params = []\n",
    "\n",
    "#For each trial\n",
    "for i in range(3):\n",
    "    data_rf = shuffle(letter_arr)\n",
    "#Data splitting, train-test-split\n",
    "    X_rf = data_rf[:, 0:-1]\n",
    "    Y_rf = data_rf[:, -1]\n",
    "    X_train_rf, X_test_rf, Y_train_rf, Y_test_rf = train_test_split(X_rf, Y_rf, test_size = 14999/19999, random_state=42)\n",
    "#Param-grid, initialize random forest class, and fitting training data with grid search.\n",
    "    params = [{'n_estimators' : [1024], 'max_features' : [1, 2, 4, 6, 8, 12, 16, 20]}]\n",
    "    forest = RandomForestClassifier()\n",
    "    grid_search_rf = GridSearchCV(forest, params, cv=5, error_score = np.nan)\n",
    "    grid_search_rf2 = grid_search_rf.fit(X_train_rf, Y_train_rf)\n",
    "#Printing and storing best params into list.\n",
    "    best_params_rf = grid_search_rf2.best_params_\n",
    "    print(\"Best params: {}\".format(best_params_rf))\n",
    "    rf_best_params.append('Trial ' + str(i + 1) + ': ' + str(best_params_rf))\n",
    "#Using best_estimator to predict training data.\n",
    "#Storing and printing training accuracy into list.\n",
    "#Using defined prediction function to calculate total accuracy.\n",
    "    train_predictions_rf = grid_search_rf2.best_estimator_.predict(X_train_rf)\n",
    "    train_accuracy_rf = prediction(train_predictions_rf, Y_train_rf)\n",
    "    print(\"Train accuracy: {}\".format(train_accuracy_rf))\n",
    "    rf_train_accuracy.append('Trial ' + str(i + 1) + ': ' + str(train_accuracy_rf))\n",
    "#Predicting Test data with best_estimator.predict.\n",
    "#Using prediction function to calculate accuracy.\n",
    "#Printing and storing Test accuracy into list.\n",
    "    test_predictions_rf = grid_search_rf2.best_estimator_.predict(X_test_rf)\n",
    "    test_accuracy_rf = prediction(test_predictions_rf, Y_test_rf)\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_rf))\n",
    "    rf_test_accuracy.append('Trial ' + str(i + 1) + ': ' + str(test_accuracy_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
